{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(51200, 51200)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open('data/aksharantar_sampled/tam/tam_train.csv') as f:\n",
    "    data_pairs = f.readlines()\n",
    "data_given = [pair.split(',')[0].strip().lower() for pair in data_pairs]\n",
    "data_target = [pair.split(',')[1].strip('\\n').strip() for pair in data_pairs]\n",
    "len(data_given), len(data_target)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building the alphabet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Alphabet():\n",
    "    def __init__(self) -> None:\n",
    "        self.letter_to_index = {}\n",
    "        self.index_to_letter = ['SOW', 'EOW', 'UNK']\n",
    "        self.letter_count = 3\n",
    "    \n",
    "    def addLetter(self, letter: str) -> None:\n",
    "        if letter not in self.letter_to_index:\n",
    "            self.letter_to_index[letter] = self.letter_count\n",
    "            self.index_to_letter.append(letter)\n",
    "            self.letter_count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29 49\n"
     ]
    }
   ],
   "source": [
    "eng_alphabet, tam_alphabet = Alphabet(), Alphabet()\n",
    "for word in data_given:\n",
    "    for letter in word:\n",
    "        eng_alphabet.addLetter(letter)\n",
    "for word in data_target:\n",
    "    for letter in word:\n",
    "        tam_alphabet.addLetter(letter)\n",
    "print(eng_alphabet.letter_count, tam_alphabet.letter_count)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Seq2Seq model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.functional import F\n",
    "\n",
    "class Encoder(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        embedding_size: int,\n",
    "        input_size: int,\n",
    "        hidden_size: int,\n",
    "        cell_type: nn.Module = nn.RNN,\n",
    "        num_layers: int = 1\n",
    "    ) -> None:\n",
    "        super().__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        self.is_lstm = (cell_type == nn.LSTM)\n",
    "        self.embedding = nn.Embedding(num_embeddings=input_size, embedding_dim=embedding_size)\n",
    "        self.encoder = cell_type(input_size=embedding_size, hidden_size=hidden_size, num_layers=num_layers) \n",
    "    \n",
    "    def forward(self, x, hidden):\n",
    "        output = self.embedding(x).reshape(1, 1, -1) \n",
    "        output, hidden = self.encoder(output, hidden)\n",
    "        return output, hidden\n",
    " \n",
    "    def initHidden(self):\n",
    "        return torch.zeros(self.num_layers, 1, self.hidden_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        embedding_size: int,\n",
    "        hidden_size: int,\n",
    "        output_size: int,\n",
    "        cell_type: nn.Module = nn.RNN,\n",
    "        num_layers: int = 1\n",
    "    ) -> None:\n",
    "        super().__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        self.is_lstm = (cell_type == nn.LSTM)\n",
    "        self.embedding = nn.Embedding(num_embeddings=output_size, embedding_dim=embedding_size)\n",
    "        self.decoder = cell_type(input_size=embedding_size, hidden_size=hidden_size, num_layers=num_layers) \n",
    "        self.out = nn.Linear(in_features=hidden_size, out_features=output_size)\n",
    "        self.softmax = nn.LogSoftmax(dim=1)\n",
    "    \n",
    "    def forward(self, x, hidden):\n",
    "        output = self.embedding(x).reshape(1, 1, -1)\n",
    "        output = F.relu(output)\n",
    "        output, hidden = self.decoder(output, hidden)\n",
    "        output = self.softmax(self.out(output[0]))\n",
    "        return output, hidden\n",
    "\n",
    "    def initHidden(self):\n",
    "        return torch.zeros(self.num_layers, 1, self.hidden_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AttnDecoder(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        embedding_size: int,\n",
    "        hidden_size: int,\n",
    "        output_size: int,\n",
    "        cell_type: nn.Module = nn.RNN,\n",
    "        num_layers: int = 1\n",
    "    ) -> None:\n",
    "        super().__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        self.embedding = nn.Embedding(num_embeddings=output_size, embedding_dim=embedding_size)\n",
    "        self.attn = nn.Linear(hidden_size+embedding_size, 100)\n",
    "        self.attn_combine = nn.Linear(hidden_size+embedding_size, self.hidden_size)\n",
    "        self.decoder = cell_type(input_size=hidden_size, hidden_size=hidden_size, num_layers=num_layers)\n",
    "        self.is_lstm = False\n",
    "        self.out = nn.Linear(in_features=hidden_size, out_features=output_size)\n",
    "    \n",
    "    def forward(self, x, hidden, output_enc):\n",
    "        embedded = self.embedding(x).reshape(1, 1, -1)\n",
    "\n",
    "        attn_wts = F.softmax(self.attn(torch.cat([embedded[0], hidden[0]], 1)), dim=1)\n",
    "        attn_applied = torch.bmm(attn_wts.unsqueeze(0), output_enc.unsqueeze(0))\n",
    "\n",
    "        output = torch.cat([embedded[0], attn_applied[0]], 1)\n",
    "        output = self.attn_combine(output).unsqueeze(0)\n",
    "\n",
    "        output = F.relu(output)\n",
    "        output, hidden = self.decoder(output, hidden)\n",
    "\n",
    "        output = F.log_softmax(self.out(output[0]), dim=1)\n",
    "        return output, hidden, attn_wts\n",
    "    \n",
    "    def initHidden(self):\n",
    "        return torch.zeros(self.num_layers, 1, self.hidden_size)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cpu'"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "device = 'cpu'\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def word_to_tensor(alphabet: Alphabet, word: str) -> torch.Tensor:\n",
    "    chars = list(alphabet.letter_to_index[letter] for letter in word) + [1]\n",
    "    return torch.tensor(chars, dtype=torch.long).reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = Encoder(8, eng_alphabet.letter_count, 128, cell_type=nn.GRU).to(device)\n",
    "# decoder = Decoder(64, tam_alphabet.letter_count, num_layers=2, cell_type=nn.GRU).to(device)\n",
    "decoder = AttnDecoder(8, 128, tam_alphabet.letter_count, cell_type=nn.GRU)\n",
    "optimizer_enc = torch.optim.Adam(encoder.parameters(), lr=1e-3)\n",
    "optimizer_dec = torch.optim.Adam(decoder.parameters(), lr=1e-3)\n",
    "loss_fn = torch.nn.NLLLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "[Batch 1000/51200] ==> 2.6866254806518555, 0.0\n",
      "[Batch 2000/51200] ==> 2.43153715133667, 0.0\n",
      "[Batch 3000/51200] ==> 2.063138246536255, 0.0\n",
      "[Batch 4000/51200] ==> 1.6504828929901123, 0.005\n",
      "[Batch 5000/51200] ==> 1.3555405139923096, 0.026005\n",
      "[Batch 6000/51200] ==> 1.116650104522705, 0.062026004999999995\n",
      "[Batch 7000/51200] ==> 0.9626758694648743, 0.11606202600500001\n",
      "[Batch 8000/51200] ==> 0.8618004322052002, 0.159116062026005\n",
      "[Batch 9000/51200] ==> 0.7446774244308472, 0.18915911606202598\n",
      "[Batch 10000/51200] ==> 0.7286422848701477, 0.264189159116062\n",
      "[Batch 11000/51200] ==> 0.6707660555839539, 0.2752641891591161\n",
      "[Batch 12000/51200] ==> 0.6304678320884705, 0.2962752641891591\n",
      "[Batch 13000/51200] ==> 0.6266735792160034, 0.32129627526418914\n",
      "[Batch 14000/51200] ==> 0.5564473867416382, 0.3673212962752642\n",
      "[Batch 15000/51200] ==> 0.5746315717697144, 0.3313673212962752\n",
      "[Batch 16000/51200] ==> 0.5427960753440857, 0.3583313673212963\n",
      "[Batch 17000/51200] ==> 0.44622108340263367, 0.4143583313673213\n",
      "[Batch 18000/51200] ==> 0.5700574517250061, 0.3594143583313673\n",
      "[Batch 19000/51200] ==> 0.45306167006492615, 0.4453594143583314\n",
      "[Batch 20000/51200] ==> 0.4578615128993988, 0.42244535941435835\n",
      "[Batch 21000/51200] ==> 0.48392733931541443, 0.41442244535941436\n",
      "[Batch 22000/51200] ==> 0.4617600440979004, 0.4244144224453594\n",
      "[Batch 23000/51200] ==> 0.45524710416793823, 0.45142441442244535\n",
      "[Batch 24000/51200] ==> 0.4330121874809265, 0.46745142441442245\n",
      "[Batch 25000/51200] ==> 0.4773399531841278, 0.43246745142441445\n",
      "[Batch 26000/51200] ==> 0.38910695910453796, 0.48643246745142443\n",
      "[Batch 27000/51200] ==> 0.45761024951934814, 0.4764864324674514\n",
      "[Batch 28000/51200] ==> 0.38696587085723877, 0.4844764864324675\n",
      "[Batch 29000/51200] ==> 0.3902353346347809, 0.48048447648643244\n",
      "[Batch 30000/51200] ==> 0.3797038793563843, 0.48548048447648645\n",
      "[Batch 31000/51200] ==> 0.4144833981990814, 0.4574854804844765\n",
      "[Batch 32000/51200] ==> 0.38666775822639465, 0.4784574854804845\n",
      "[Batch 33000/51200] ==> 0.37838560342788696, 0.5054784574854805\n",
      "[Batch 34000/51200] ==> 0.40938112139701843, 0.4915054784574855\n",
      "[Batch 35000/51200] ==> 0.4180959463119507, 0.4924915054784575\n",
      "[Batch 36000/51200] ==> 0.41551336646080017, 0.48149249150547846\n",
      "[Batch 37000/51200] ==> 0.386688768863678, 0.5114814924915055\n",
      "[Batch 38000/51200] ==> 0.38827016949653625, 0.5025114814924915\n",
      "[Batch 39000/51200] ==> 0.44499289989471436, 0.4585025114814925\n",
      "[Batch 40000/51200] ==> 0.3692379295825958, 0.5264585025114815\n",
      "[Batch 41000/51200] ==> 0.3913430869579315, 0.47452645850251146\n",
      "[Batch 42000/51200] ==> 0.4117257595062256, 0.4814745264585025\n",
      "[Batch 43000/51200] ==> 0.31179583072662354, 0.5354814745264584\n",
      "[Batch 44000/51200] ==> 0.4077398478984833, 0.4675354814745265\n",
      "[Batch 45000/51200] ==> 0.37926995754241943, 0.49746753548147454\n",
      "[Batch 46000/51200] ==> 0.35853487253189087, 0.5254974675354815\n",
      "[Batch 47000/51200] ==> 0.35324403643608093, 0.5315254974675355\n",
      "[Batch 48000/51200] ==> 0.3423992693424225, 0.5305315254974675\n",
      "[Batch 49000/51200] ==> 0.36133676767349243, 0.5345305315254975\n",
      "[Batch 50000/51200] ==> 0.3767194151878357, 0.5165345305315254\n",
      "[Batch 51000/51200] ==> 0.32214459776878357, 0.5315165345305315\n",
      "Epoch 2/10\n",
      "[Batch 1000/51200] ==> 0.3632330596446991, 0.536\n",
      "[Batch 2000/51200] ==> 0.3233981430530548, 0.551536\n",
      "[Batch 3000/51200] ==> 0.3089061677455902, 0.564551536\n",
      "[Batch 4000/51200] ==> 0.34181973338127136, 0.5395645515359999\n",
      "[Batch 5000/51200] ==> 0.3123774230480194, 0.542539564551536\n",
      "[Batch 6000/51200] ==> 0.435489296913147, 0.4795425395645515\n",
      "[Batch 7000/51200] ==> 0.31833961606025696, 0.5344795425395646\n",
      "[Batch 8000/51200] ==> 0.35680192708969116, 0.5105344795425395\n",
      "[Batch 9000/51200] ==> 0.3124524652957916, 0.5655105344795426\n",
      "[Batch 10000/51200] ==> 0.3205989599227905, 0.5595655105344794\n",
      "[Batch 11000/51200] ==> 0.36090579628944397, 0.5305595655105344\n",
      "[Batch 12000/51200] ==> 0.35695502161979675, 0.5355305595655105\n",
      "[Batch 13000/51200] ==> 0.35169893503189087, 0.5365355305595655\n",
      "[Batch 14000/51200] ==> 0.34305572509765625, 0.5295365355305596\n",
      "[Batch 15000/51200] ==> 0.2917412519454956, 0.5565295365355305\n",
      "[Batch 16000/51200] ==> 0.3373802900314331, 0.5365565295365355\n",
      "[Batch 17000/51200] ==> 0.276031494140625, 0.5675365565295365\n",
      "[Batch 18000/51200] ==> 0.31464889645576477, 0.5475675365565296\n",
      "[Batch 19000/51200] ==> 0.2805732190608978, 0.5755475675365564\n",
      "[Batch 20000/51200] ==> 0.33465731143951416, 0.5595755475675366\n",
      "[Batch 21000/51200] ==> 0.3919646441936493, 0.5325595755475675\n",
      "[Batch 22000/51200] ==> 0.3210568130016327, 0.5605325595755476\n",
      "[Batch 23000/51200] ==> 0.33111417293548584, 0.5615605325595756\n",
      "[Batch 24000/51200] ==> 0.2919263541698456, 0.5495615605325596\n",
      "[Batch 25000/51200] ==> 0.4103638231754303, 0.49854956156053254\n",
      "[Batch 26000/51200] ==> 0.31445103883743286, 0.5374985495615606\n",
      "[Batch 27000/51200] ==> 0.38488131761550903, 0.5065374985495615\n",
      "[Batch 28000/51200] ==> 0.3263328969478607, 0.5475065374985495\n",
      "[Batch 29000/51200] ==> 0.379397451877594, 0.5455475065374985\n",
      "[Batch 30000/51200] ==> 0.30842655897140503, 0.5855455475065375\n",
      "[Batch 31000/51200] ==> 0.31573712825775146, 0.5605855455475065\n",
      "[Batch 32000/51200] ==> 0.3658201992511749, 0.5285605855455475\n",
      "[Batch 33000/51200] ==> 0.3203962445259094, 0.5585285605855457\n",
      "[Batch 34000/51200] ==> 0.3616189956665039, 0.5395585285605855\n",
      "[Batch 35000/51200] ==> 0.3328172266483307, 0.5265395585285605\n",
      "[Batch 36000/51200] ==> 0.3522806167602539, 0.5175265395585286\n",
      "[Batch 37000/51200] ==> 0.32508033514022827, 0.5455175265395585\n",
      "[Batch 38000/51200] ==> 0.36153993010520935, 0.5175455175265395\n",
      "[Batch 39000/51200] ==> 0.3492211103439331, 0.5545175455175265\n",
      "[Batch 40000/51200] ==> 0.3300057649612427, 0.5455545175455174\n",
      "[Batch 41000/51200] ==> 0.35400527715682983, 0.5085455545175455\n",
      "[Batch 42000/51200] ==> 0.3078964650630951, 0.5525085455545176\n",
      "[Batch 43000/51200] ==> 0.31644415855407715, 0.5525525085455545\n",
      "[Batch 44000/51200] ==> 0.3458312153816223, 0.5485525525085455\n",
      "[Batch 45000/51200] ==> 0.3659001886844635, 0.5195485525525085\n",
      "[Batch 46000/51200] ==> 0.351973295211792, 0.5165195485525526\n",
      "[Batch 47000/51200] ==> 0.31856730580329895, 0.5545165195485525\n",
      "[Batch 48000/51200] ==> 0.3467573821544647, 0.5245545165195485\n",
      "[Batch 49000/51200] ==> 0.377157986164093, 0.5215245545165195\n",
      "[Batch 50000/51200] ==> 0.314432293176651, 0.5515215245545165\n",
      "[Batch 51000/51200] ==> 0.2983393669128418, 0.5595515215245546\n",
      "Epoch 3/10\n",
      "[Batch 1000/51200] ==> 0.3107832372188568, 0.575\n",
      "[Batch 2000/51200] ==> 0.2552451491355896, 0.5745750000000001\n",
      "[Batch 3000/51200] ==> 0.3139013946056366, 0.572574575\n",
      "[Batch 4000/51200] ==> 0.32733285427093506, 0.560572574575\n",
      "[Batch 5000/51200] ==> 0.3560703992843628, 0.539560572574575\n",
      "[Batch 6000/51200] ==> 0.32849225401878357, 0.5635395605725746\n",
      "[Batch 7000/51200] ==> 0.303026020526886, 0.5495635395605725\n",
      "[Batch 8000/51200] ==> 0.3183044195175171, 0.5545495635395606\n",
      "[Batch 9000/51200] ==> 0.3470493257045746, 0.5525545495635396\n",
      "[Batch 10000/51200] ==> 0.3344426155090332, 0.5845525545495636\n",
      "[Batch 11000/51200] ==> 0.2907748818397522, 0.5575845525545495\n",
      "[Batch 12000/51200] ==> 0.33726397156715393, 0.5635575845525546\n",
      "[Batch 13000/51200] ==> 0.30122798681259155, 0.5465635575845526\n",
      "[Batch 14000/51200] ==> 0.32179272174835205, 0.5555465635575845\n",
      "[Batch 15000/51200] ==> 0.288106232881546, 0.5545555465635575\n",
      "[Batch 16000/51200] ==> 0.3379709720611572, 0.5295545555465635\n",
      "[Batch 17000/51200] ==> 0.2810300886631012, 0.5585295545555466\n",
      "[Batch 18000/51200] ==> 0.33119916915893555, 0.5275585295545555\n",
      "[Batch 19000/51200] ==> 0.3209952712059021, 0.5415275585295546\n",
      "[Batch 20000/51200] ==> 0.3641277849674225, 0.5455415275585296\n",
      "[Batch 21000/51200] ==> 0.3716236352920532, 0.5335455415275585\n",
      "[Batch 22000/51200] ==> 0.3112896978855133, 0.5675335455415276\n",
      "[Batch 23000/51200] ==> 0.3476701080799103, 0.5395675335455415\n",
      "[Batch 24000/51200] ==> 0.37441006302833557, 0.5195395675335456\n",
      "[Batch 25000/51200] ==> 0.4025900661945343, 0.5075195395675336\n",
      "[Batch 26000/51200] ==> 0.297913521528244, 0.5675075195395675\n",
      "[Batch 27000/51200] ==> 0.356063574552536, 0.5445675075195395\n",
      "[Batch 28000/51200] ==> 0.32243505120277405, 0.5755445675075196\n",
      "[Batch 29000/51200] ==> 0.35839733481407166, 0.5505755445675075\n",
      "[Batch 30000/51200] ==> 0.38951486349105835, 0.4945505755445675\n",
      "[Batch 31000/51200] ==> 0.36332717537879944, 0.5194945505755445\n",
      "[Batch 32000/51200] ==> 0.36568304896354675, 0.5035194945505755\n",
      "[Batch 33000/51200] ==> 0.34110963344573975, 0.5245035194945505\n",
      "[Batch 34000/51200] ==> 0.3899727165699005, 0.5105245035194945\n",
      "[Batch 35000/51200] ==> 0.37325984239578247, 0.5165105245035195\n",
      "[Batch 36000/51200] ==> 0.35410234332084656, 0.5155165105245034\n",
      "[Batch 37000/51200] ==> 0.3273133337497711, 0.5485155165105245\n",
      "[Batch 38000/51200] ==> 0.33150896430015564, 0.5515485155165105\n",
      "[Batch 39000/51200] ==> 0.37940919399261475, 0.5345515485155166\n",
      "[Batch 40000/51200] ==> 0.36371946334838867, 0.5225345515485156\n",
      "[Batch 41000/51200] ==> 0.39076852798461914, 0.49352253455154854\n",
      "[Batch 42000/51200] ==> 0.3418564200401306, 0.5324935225345515\n",
      "[Batch 43000/51200] ==> 0.2874892055988312, 0.5875324935225346\n",
      "[Batch 44000/51200] ==> 0.3461870551109314, 0.5345875324935225\n",
      "[Batch 45000/51200] ==> 0.34007588028907776, 0.5775345875324935\n",
      "[Batch 46000/51200] ==> 0.3309020400047302, 0.5305775345875324\n",
      "[Batch 47000/51200] ==> 0.3274131417274475, 0.5295305775345875\n",
      "[Batch 48000/51200] ==> 0.39478689432144165, 0.5015295305775346\n",
      "[Batch 49000/51200] ==> 0.349619597196579, 0.5045015295305775\n",
      "[Batch 50000/51200] ==> 0.47441884875297546, 0.4475045015295306\n",
      "[Batch 51000/51200] ==> 0.49485301971435547, 0.44344750450152953\n",
      "Epoch 4/10\n",
      "[Batch 1000/51200] ==> 0.36730897426605225, 0.513\n",
      "[Batch 2000/51200] ==> 0.320574551820755, 0.542513\n",
      "[Batch 3000/51200] ==> 0.32013800740242004, 0.564542513\n",
      "[Batch 4000/51200] ==> 0.31063002347946167, 0.573564542513\n",
      "[Batch 5000/51200] ==> 0.34856873750686646, 0.499573564542513\n",
      "[Batch 6000/51200] ==> 0.5737304091453552, 0.3844995735645425\n",
      "[Batch 7000/51200] ==> 0.42813462018966675, 0.46538449957356454\n",
      "[Batch 8000/51200] ==> 0.39746853709220886, 0.4764653844995736\n",
      "[Batch 9000/51200] ==> 0.36982935667037964, 0.5214764653844995\n",
      "[Batch 10000/51200] ==> 0.38011226058006287, 0.5395214764653845\n",
      "[Batch 11000/51200] ==> 0.4672694504261017, 0.45253952147646537\n",
      "[Batch 12000/51200] ==> 0.489202618598938, 0.45145253952147646\n",
      "[Batch 13000/51200] ==> 0.38075074553489685, 0.5034514525395215\n",
      "[Batch 14000/51200] ==> 0.36295047402381897, 0.5055034514525395\n",
      "[Batch 15000/51200] ==> 0.41173887252807617, 0.4765055034514526\n",
      "[Batch 16000/51200] ==> 0.48233678936958313, 0.42247650550345145\n",
      "[Batch 17000/51200] ==> 0.39229220151901245, 0.4644224765055035\n",
      "[Batch 18000/51200] ==> 0.3600904047489166, 0.4944644224765055\n",
      "[Batch 19000/51200] ==> 0.35140761733055115, 0.5334944644224765\n",
      "[Batch 20000/51200] ==> 0.3711335062980652, 0.49153349446442246\n",
      "[Batch 21000/51200] ==> 0.5187758207321167, 0.41949153349446444\n",
      "[Batch 22000/51200] ==> 0.43110373616218567, 0.47341949153349444\n",
      "[Batch 23000/51200] ==> 0.4110512137413025, 0.4944734194915335\n",
      "[Batch 24000/51200] ==> 0.5519533157348633, 0.36149447341949154\n",
      "[Batch 25000/51200] ==> 0.5252898931503296, 0.3763614944734195\n",
      "[Batch 26000/51200] ==> 0.47276076674461365, 0.4413763614944734\n",
      "[Batch 27000/51200] ==> 0.4243629574775696, 0.45544137636149445\n",
      "[Batch 28000/51200] ==> 0.42639318108558655, 0.44745544137636145\n",
      "[Batch 29000/51200] ==> 0.5343965291976929, 0.38144745544137637\n",
      "[Batch 30000/51200] ==> 0.46821078658103943, 0.4363814474554414\n",
      "[Batch 31000/51200] ==> 0.4520959258079529, 0.4774363814474555\n",
      "[Batch 32000/51200] ==> 0.4753926694393158, 0.4144774363814474\n",
      "[Batch 33000/51200] ==> 0.48276486992836, 0.42641447743638144\n",
      "[Batch 34000/51200] ==> 0.7413100600242615, 0.25942641447743636\n",
      "[Batch 35000/51200] ==> 0.6392661333084106, 0.31825942641447746\n",
      "[Batch 36000/51200] ==> 0.47982847690582275, 0.4113182594264144\n",
      "[Batch 37000/51200] ==> 0.3886694014072418, 0.4914113182594264\n",
      "[Batch 38000/51200] ==> 0.43373990058898926, 0.47349141131825945\n",
      "[Batch 39000/51200] ==> 0.4551341235637665, 0.46247349141131827\n",
      "[Batch 40000/51200] ==> 0.4518100917339325, 0.4604624734914113\n",
      "[Batch 41000/51200] ==> 0.6305369734764099, 0.3354604624734914\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[49], line 60\u001b[0m\n\u001b[1;32m     57\u001b[0m         \u001b[39mif\u001b[39;00m input_dec\u001b[39m.\u001b[39mitem() \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[1;32m     58\u001b[0m             \u001b[39mbreak\u001b[39;00m\n\u001b[0;32m---> 60\u001b[0m loss\u001b[39m.\u001b[39;49mbackward()\n\u001b[1;32m     61\u001b[0m avg_loss \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m loss\u001b[39m.\u001b[39mdetach() \u001b[39m/\u001b[39m target_len\n\u001b[1;32m     63\u001b[0m \u001b[39mif\u001b[39;00m prediction \u001b[39m==\u001b[39m data_target[train_index]\u001b[39m+\u001b[39m\u001b[39m'\u001b[39m\u001b[39mEOW\u001b[39m\u001b[39m'\u001b[39m:\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/_tensor.py:488\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    478\u001b[0m \u001b[39mif\u001b[39;00m has_torch_function_unary(\u001b[39mself\u001b[39m):\n\u001b[1;32m    479\u001b[0m     \u001b[39mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    480\u001b[0m         Tensor\u001b[39m.\u001b[39mbackward,\n\u001b[1;32m    481\u001b[0m         (\u001b[39mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    486\u001b[0m         inputs\u001b[39m=\u001b[39minputs,\n\u001b[1;32m    487\u001b[0m     )\n\u001b[0;32m--> 488\u001b[0m torch\u001b[39m.\u001b[39;49mautograd\u001b[39m.\u001b[39;49mbackward(\n\u001b[1;32m    489\u001b[0m     \u001b[39mself\u001b[39;49m, gradient, retain_graph, create_graph, inputs\u001b[39m=\u001b[39;49minputs\n\u001b[1;32m    490\u001b[0m )\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/autograd/__init__.py:197\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    192\u001b[0m     retain_graph \u001b[39m=\u001b[39m create_graph\n\u001b[1;32m    194\u001b[0m \u001b[39m# The reason we repeat same the comment below is that\u001b[39;00m\n\u001b[1;32m    195\u001b[0m \u001b[39m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    196\u001b[0m \u001b[39m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 197\u001b[0m Variable\u001b[39m.\u001b[39;49m_execution_engine\u001b[39m.\u001b[39;49mrun_backward(  \u001b[39m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    198\u001b[0m     tensors, grad_tensors_, retain_graph, create_graph, inputs,\n\u001b[1;32m    199\u001b[0m     allow_unreachable\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, accumulate_grad\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "teacher_forcing_ratio = 0.5\n",
    "\n",
    "for epoch in range(10):\n",
    "    print(f'Epoch {epoch+1}/10')\n",
    "    avg_loss, avg_score = 0.0, 0.0\n",
    "    for train_index in range(len(data_given)):\n",
    "    # for train_index in range(1000):\n",
    "        hidden_enc = encoder.initHidden().to(device)\n",
    "        cell_enc = encoder.initHidden().to(device)\n",
    "\n",
    "        optimizer_enc.zero_grad()\n",
    "        optimizer_dec.zero_grad()\n",
    "\n",
    "        input_vector = word_to_tensor(eng_alphabet, data_given[train_index]).to(device)\n",
    "        input_len = len(input_vector)\n",
    "\n",
    "        outputs_enc = torch.zeros(100, encoder.hidden_size)\n",
    "\n",
    "        loss = 0.0\n",
    "\n",
    "        for i, char in enumerate(input_vector):\n",
    "            if encoder.is_lstm:\n",
    "                output_enc, (hidden_enc, cell_enc) = encoder(char, (hidden_enc, cell_enc))\n",
    "            else:\n",
    "                output_enc, hidden_enc = encoder(char, hidden_enc)\n",
    "            outputs_enc[i] = output_enc[0, 0]\n",
    "        \n",
    "        input_dec = torch.tensor([[0]]).to(device)\n",
    "        target_vector = word_to_tensor(tam_alphabet, data_target[train_index]).to(device)\n",
    "        target_len = len(target_vector)\n",
    "\n",
    "        if decoder.is_lstm:\n",
    "            cell_dec = torch.cat([cell_enc[-1].reshape(1, 1, -1)]*decoder.num_layers).to(device)\n",
    "        hidden_dec = torch.cat([hidden_enc[-1].reshape(1, 1, -1)]*decoder.num_layers).to(device)\n",
    "\n",
    "        use_teacher_forcing = True if torch.rand(1) < teacher_forcing_ratio else False\n",
    "        prediction = ''\n",
    "\n",
    "        if use_teacher_forcing:\n",
    "            for di in range(target_len):\n",
    "                if decoder.is_lstm:\n",
    "                    output_dec, (hidden_dec, cell_dec) = decoder(input_dec, (hidden_dec, cell_dec))\n",
    "                else:\n",
    "                    output_dec, hidden_dec, attn = decoder(input_dec, hidden_dec, outputs_enc)\n",
    "                loss += loss_fn(output_dec, target_vector[di])\n",
    "                input_dec = target_vector[di]\n",
    "                prediction += tam_alphabet.index_to_letter[output_dec.argmax(dim=1).squeeze().detach()]\n",
    "        else:\n",
    "            for di in range(target_len):\n",
    "                if decoder.is_lstm:\n",
    "                    output_dec, (hidden_dec, cell_dec) = decoder(input_dec, (hidden_dec, cell_dec))\n",
    "                else:\n",
    "                    output_dec, hidden_dec, attn = decoder(input_dec, hidden_dec, outputs_enc)\n",
    "                input_dec = output_dec.argmax(dim=1).squeeze().detach()\n",
    "                loss += loss_fn(output_dec, target_vector[di])\n",
    "                prediction += tam_alphabet.index_to_letter[input_dec.squeeze()]\n",
    "                if input_dec.item() == 1:\n",
    "                    break\n",
    "        \n",
    "        loss.backward()\n",
    "        avg_loss += loss.detach() / target_len\n",
    "\n",
    "        if prediction == data_target[train_index]+'EOW':\n",
    "            avg_score += 1.\n",
    "\n",
    "        optimizer_enc.step()\n",
    "        optimizer_dec.step()\n",
    "\n",
    "        if (train_index+1) % 1000 == 0:\n",
    "            avg_loss /= 1000\n",
    "            avg_score /= 1000\n",
    "            print(f'[Batch {train_index+1}/{len(data_given)}] ==> {avg_loss}, {avg_score}')\n",
    "            avg_loss = 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "chosen_index = 0\n",
    "\n",
    "with torch.inference_mode():\n",
    "    input_vector = word_to_tensor(eng_alphabet, data_given[chosen_index])\n",
    "    input_len = len(input_vector)\n",
    "    hidden_enc = encoder.initHidden().to(device)\n",
    "\n",
    "    for char in input_vector:\n",
    "        output_enc, hidden_enc = encoder(char.to(device), hidden_enc)\n",
    "\n",
    "    input_dec = torch.tensor([[0]])\n",
    "    hidden_dec = hidden_enc.to(device)\n",
    "\n",
    "    translit_chars = []\n",
    "\n",
    "    max_length = 100\n",
    "    while max_length > 0:\n",
    "        output_dec, hidden_dec = decoder(input_dec.to(device), hidden_dec)\n",
    "        pred_char_index = output_dec.data.argmax()\n",
    "        if pred_char_index.item() == 1:\n",
    "            translit_chars.append('EOW')\n",
    "            break\n",
    "        else:\n",
    "            translit_chars.append(tam_alphabet.index_to_letter[pred_char_index])\n",
    "        input_dec = pred_char_index.squeeze().detach()\n",
    "        max_length -= 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('தொட்டர்யார', 'தொட்டாச்சார்ய', 'thottacharya')"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "''.join(translit_chars[:-1]), data_target[chosen_index], data_given[chosen_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4096, 4096)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open('data/aksharantar_sampled/tam/tam_valid.csv') as f:\n",
    "    val_data_pairs = f.readlines()\n",
    "val_data_given = [pair.split(',')[0].strip().lower() for pair in val_data_pairs]\n",
    "val_data_target = [pair.split(',')[1].strip('\\n').strip() for pair in val_data_pairs]\n",
    "len(val_data_given), len(val_data_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[49], line 25\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m     24\u001b[0m         translit_chars\u001b[39m.\u001b[39mappend(tam_alphabet\u001b[39m.\u001b[39mindex_to_letter[pred_char_index])\n\u001b[0;32m---> 25\u001b[0m     input_dec \u001b[39m=\u001b[39m pred_char_index\u001b[39m.\u001b[39;49msqueeze()\u001b[39m.\u001b[39;49mdetach()\n\u001b[1;32m     26\u001b[0m     max_length \u001b[39m-\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m     27\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39m'\u001b[39m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mjoin(translit_chars) \u001b[39m==\u001b[39m val_data_target[chosen_index]\u001b[39m+\u001b[39m\u001b[39m'\u001b[39m\u001b[39mEOW\u001b[39m\u001b[39m'\u001b[39m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "with torch.inference_mode():\n",
    "    acc = 0.0\n",
    "    for chosen_index in range(len(val_data_given)):\n",
    "        input_vector = word_to_tensor(eng_alphabet, val_data_given[chosen_index])\n",
    "        input_len = len(input_vector)\n",
    "        hidden_enc = encoder.initHidden().to(device)\n",
    "\n",
    "        for char in input_vector:\n",
    "            output_enc, hidden_enc = encoder(char.to(device), hidden_enc)\n",
    "\n",
    "        input_dec = torch.tensor([[0]])\n",
    "        hidden_dec = hidden_enc.to(device)\n",
    "\n",
    "        translit_chars = []\n",
    "\n",
    "        max_length = 100\n",
    "        while max_length > 0:\n",
    "            output_dec, hidden_dec = decoder(input_dec.to(device), hidden_dec)\n",
    "            pred_char_index = output_dec.data.argmax()\n",
    "            if pred_char_index.item() == 1:\n",
    "                translit_chars.append('EOW')\n",
    "                break\n",
    "            else:\n",
    "                translit_chars.append(tam_alphabet.index_to_letter[pred_char_index])\n",
    "            input_dec = pred_char_index.squeeze().detach()\n",
    "            max_length -= 1\n",
    "        if ''.join(translit_chars) == val_data_target[chosen_index]+'EOW':\n",
    "            acc += 1.\n",
    "    acc /= len(val_data_given)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
